# ğŸŒŸ Progressive Multi-Domain Adaptation Network with Reinforced Self-Constructed Graphs ğŸš€

Welcome to the official repository for our paper **"A Progressive Multi-Domain Adaptation Network with Reinforced Self-Constructed Graphs for Cross-Subject EEG-Based Emotion and Consciousness Recognition"**, published in *IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE)*, 2025! ğŸ‰

This repository contains the complete implementation of our innovative framework for cross-subject EEG-based emotion and consciousness recognition. ğŸ§ âœ¨

## ğŸ“– Overview

Our project introduces a cutting-edge **Progressive Multi-Domain Adaptation Network** that leverages reinforced self-constructed graphs to address domain shift and subject variability in EEG data. This approach enhances the robustness and accuracy of emotion and consciousness recognition across subjects, paving the way for advanced neural systems applications. ğŸŒ

## ğŸ› ï¸ Prerequisites

To get started, ensure you have the following:

- ğŸ Python 3.8 or higher
- ğŸ“¦ Required Python packages :
  - NumPy
  - PyTorch
  - SciPy
  - Scikit-learn
  - Pandas
  - ......
- ğŸ“Š Datasets: SEED and SEED-IV
- ğŸ’» A computing environment (GPU recommended for faster training âš¡)

## âš™ï¸ Installation

1. Clone this repository to your local machine:

   ```bash
   git clone https://github.com/your-username/your-repo-name.git
   cd your-repo-name
   ```

2. Install the required dependencies:

   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“‚ Dataset Preparation

This project uses the **SEED** and **SEED-IV** datasets for EEG-based emotion recognition. Follow these steps to prepare the data:

1. ğŸ“¥ Download the SEED and/or SEED-IV datasets from their official sources.
2. ğŸ“‚ Place the extracted dataset files (DE) in the appropriate directory.
3. âœ… Ensure the dataset files are correctly formatted and accessible for preprocessing.

## ğŸš€ Running the Experiments

Follow these steps to run the experiments and reproduce our results:

1. **Create a Result Directory** ğŸ“
   In the project root directory, create an empty folder named `result` to store outputs:

   ```bash
   mkdir result
   ```

2. **Preprocess the Data** ğŸ› ï¸
   Run the preprocessing script to partition the dataset into source, target, and mixed domains:

   ```bash
   python datapipe.py
   ```

   **Note**: Update the dataset paths in `datapipe.py` to match your SEED/SEED-IV data locations.

3. **Run the Main Script** â–¶ï¸
   Execute the main script to train and evaluate the model:

   ```bash
   python main.py
   ```

   The script will handle model training, evaluation, and save results to the `result` directory.

## ğŸ“ˆ Output

- ğŸ“œ Training logs and model checkpoints will be saved in the `./result` directory.
- ğŸ“Š Evaluation metrics (e.g., accuracy, F1-score) for emotion and consciousness recognition will be logged and saved as summary files.

## ğŸ“ Citation

If you find our work inspiring or use this code, please cite our paper:

```bibtex
@article{Chen2025progressive,
  title={A Progressive Multi-Domain Adaptation Network with Reinforced Self-Constructed Graphs for Cross-Subject EEG-Based Emotion and Consciousness Recognition},
  author={Chen, Rongtao and Xie, Chuwen and Zhang, Jiahui and You, Qi and Pan, Jiahui},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year={2025},
  publisher={IEEE}
}
```

## ğŸ“¬ Contact

For questions, feedback, or issues, please:

- ğŸ“§ Reach out to [chenrongtao@m.scnu.edu.cn](mailto:chenrongtao@m.scnu.edu.cn).

Thank you for exploring our work! We hope this repository sparks innovation and advances your research journey! ğŸŒŸ